# -*- coding: utf-8 -*-
# """Copy of AIProject.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1yIqz6xyC9yN4xFKkuAVXmMC3feda12ZJ

# # Loading Dependencies
# """

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd 
import numpy as np
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import scipy as scipy
from scipy import stats

from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

import warnings
warnings.filterwarnings("ignore")

"""# Data Loading"""

df = pd.read_csv('data.csv')
df.head()

df.info()

# correlation_matrix = df.corr()
# print(correlation_matrix)

df.head()

"""# Data Cleaning"""

df.isnull().sum()

drop_df = df.dropna()

drop_df.isnull().sum()

drop_df.info()

no_duplicates = drop_df.drop_duplicates()

no_duplicates.info()

"""# One Hot Categorical Endcoding"""

df['Category'].unique()

# df = pd.get_dummies(df, columns=['Category'], prefix='Category', dtype='int64')

df['Color'].unique()

# df = pd.get_dummies(df, columns=['Color'], prefix='Color', dtype='int64')

df['Size'].unique()

# df = pd.get_dummies(df, columns=['Size'], prefix='Size', dtype='int64')

df['Material'].unique()

# df = pd.get_dummies(df, columns=['Material'], prefix='Material', dtype='int64')

df['Brand'].unique()

# df = pd.get_dummies(df, columns=['Brand'], prefix='Brand', dtype='int64')

# df

encoder = OrdinalEncoder()
df[['Brand','Category','Color','Size','Material']] = encoder.fit_transform(df[['Brand','Category','Color','Size','Material']])



"""# Min Max Scaling"""

df.describe()

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

standardized_data = scaler.fit_transform(df)

standardized_df = pd.DataFrame(standardized_data, columns=df.columns)

df.info()

df.head()

standardized_df.head()

standardized_df.describe()

"""# Removing Outliers"""

import seaborn as sns

"""Z scaling"""

upper_limit = df['Price'].mean() + 3*df['Price'].std()
lower_limit = df['Price'].mean() - 3*df['Price'].std()
print('upper limit:', upper_limit)
print('lower limit:', lower_limit)
df.loc[(df['Price'] > upper_limit) | (df['Price'] < lower_limit)]
new_df = df.loc[(df['Price'] <= upper_limit) & (df['Price'] >= lower_limit)]
print('before removing outliers:', len(df))
print('after removing outliers:',len(new_df))
print('outliers:', len(df)-len(new_df))
sns.boxplot(new_df['Price'])
new_df = df.copy()
new_df.loc[(new_df['Price']>=upper_limit),'Price'] = upper_limit
new_df.loc[(new_df['Price']<=lower_limit), 'Price'] = lower_limit
sns.boxplot(new_df['Price'])

"""IQR"""

q1 = df['Price'].quantile(0.25)
q3 = df['Price'].quantile(0.75)
iqr = q3-q1
q1, q3, iqr
upper_limit = q3 + (1.5 * iqr)
lower_limit = q1 - (1.5 * iqr)
lower_limit, upper_limit
sns.boxplot(df['Price'])
df.loc[(df['Price'] > upper_limit) | (df['Price'] < lower_limit)]
new_df = df.loc[(df['Price'] <= upper_limit) & (df['Price'] >= lower_limit)]
print('before removing outliers:', len(df))
print('after removing outliers:',len(new_df))
print('outliers:', len(df)-len(new_df))
sns.boxplot(new_df['Price'])
new_df = df.copy()
new_df.loc[(new_df['Price']>upper_limit), 'Price'] = upper_limit
new_df.loc[(new_df['Price']<lower_limit), 'Price'] = lower_limit

sns.boxplot(new_df['Price'])

"""Percentile"""

upper_limit = df['Price'].quantile(0.99)
lower_limit = df['Price'].quantile(0.01)
print('upper limit:', upper_limit)
print('lower limit:', lower_limit)
sns.boxplot(df['Price'])
df.loc[(df['Price'] > upper_limit) | (df['Price'] < lower_limit)]
new_df = df.loc[(df['Price'] <= upper_limit) & (df['Price'] >= lower_limit)]
print('before removing outliers:', len(df))
print('after removing outliers:',len(new_df))
print('outliers:', len(df)-len(new_df))
sns.boxplot(new_df['Price'])

new_df = df.copy()
new_df.loc[(new_df['Price']>upper_limit), 'Price'] = upper_limit
new_df.loc[(new_df['Price']<lower_limit), 'Price'] = lower_limit
sns.boxplot(new_df['Price'])
sns.distplot(df['Price'])
sns.distplot(new_df['Price'])

from sklearn.linear_model import LinearRegression
lr_model = LinearRegression()

standardized_df

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn import metrics

X = df.drop(['Price'],axis=1)
# X = X.drop(['Brand'],axis=1)
# X = X.drop(['Size'],axis=1)
# X = X.drop(['Category'],axis=1)
# X = X.drop(['Material'],axis=1)
Y = df['Price']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=2)
X

"""**Decision Tree**"""

# from sklearn.tree import DecisionTreeRegressor
# from sklearn.metrics import mean_squared_error

# # Assuming X_train, X_test, Y_train, Y_test are already defined

# # Initialize the DecisionTreeRegressor
# model = DecisionTreeRegressor(random_state=42)

# # Train the model on the training data
# model.fit(X_train, Y_train)

# # Make predictions on the testing data
# Y_pred = model.predict(X_test)

# # Evaluate the model using mean squared error
# mse = mean_squared_error(Y_test, Y_pred)
# print("Mean Squared Error:", mse)

# #finding the root square value
# from sklearn.metrics import mean_squared_error, r2_score
# import numpy as np

# # Calculate Mean Squared Error (MSE)
# mse = mean_squared_error(Y_test, Y_pred)
# print("Mean Squared Error:", mse)

# # Calculate Root Mean Squared Error (RMSE)
# rmse = np.sqrt(mse)
# print("Root Mean Squared Error:", rmse)

# # Calculate R-squared (R2) score
# r2 = r2_score(Y_test, Y_pred)
# print("R-squared (R2) Score:", r2)

# # tunning the model using best hyperparameters(grid search)
# from sklearn.tree import DecisionTreeRegressor
# from sklearn.model_selection import GridSearchCV

# # Initialize the DecisionTreeRegressor
# model = DecisionTreeRegressor(random_state=42)

# # Define the hyperparameters to tune
# param_grid = {
#     'max_depth': [None, 5, 10, 15],  # Maximum depth of the tree
#     'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node
#     'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node
#     'max_features': ['auto', 'sqrt', 'log2']  # Maximum number of features to consider for each split
# }

# # Initialize GridSearchCV
# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2')

# # Perform grid search to find the best hyperparameters
# grid_search.fit(X_train, Y_train)

# # Get the best hyperparameters
# best_params = grid_search.best_params_
# print("Best Hyperparameters:", best_params)

# # Use the best model for prediction
# best_model = grid_search.best_estimator_
# Y_pred_tuned = best_model.predict(X_test)

# # Evaluate the model using mean squared error
# mse_tuned = mean_squared_error(Y_test, Y_pred_tuned)
# print("Mean Squared Error (Tuned):", mse_tuned)

# # Calculate R-squared (R2) score for the tuned model
# r2_tuned = r2_score(Y_test, Y_pred_tuned)
# print("R-squared (R2) Score (Tuned):", r2_tuned)

# from sklearn.tree import DecisionTreeRegressor
# from sklearn.model_selection import GridSearchCV
# from sklearn.metrics import mean_squared_error, r2_score
# import numpy as np

# # Initialize the DecisionTreeRegressor
# model = DecisionTreeRegressor(random_state=42)

# # Define the expanded hyperparameters to tune
# param_grid = {
#     'max_depth': [None, 5, 10, 15, 20],  # Maximum depth of the tree
#     'min_samples_split': [2, 5, 10, 15, 20],  # Minimum samples required to split a node
#     'min_samples_leaf': [1, 2, 4, 8, 16],  # Minimum samples required at a leaf node
#     'max_features': ['auto', 'sqrt', 'log2', None],  # Maximum number of features to consider for each split
#     'ccp_alpha': [0.0, 0.01, 0.1, 1.0]  # Complexity parameter used for Minimal Cost-Complexity Pruning
# }

# # Initialize GridSearchCV
# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

# # Perform grid search to find the best hyperparameters
# grid_search.fit(X_train, Y_train)

# # Get the best hyperparameters
# best_params = grid_search.best_params_
# print("Best Hyperparameters:", best_params)

# # Use the best model for prediction
# best_model = grid_search.best_estimator_
# Y_pred = best_model.predict(X_test)

# # Calculate RMSE for the best model
# rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))
# print("Root Mean Squared Error (RMSE) for Best Model:", rmse)

# # Calculate R2 score for the best model
# r2 = r2_score(Y_test, Y_pred)
# print("R-squared (R2) Score for Best Model:", r2)

# # feature importance
# from sklearn.tree import DecisionTreeRegressor
# import matplotlib.pyplot as plt

# # Assuming X_train and Y_train are your training features and target variable
# # Assuming X_test and Y_test are your testing features and target variable

# # Initialize the DecisionTreeRegressor
# model = DecisionTreeRegressor(random_state=42)

# # Fit the model
# model.fit(X_train, Y_train)

# # Get feature importances
# feature_importances = model.feature_importances_

# # Sort feature importances in descending order
# indices = np.argsort(feature_importances)[::-1]

# # Print feature ranking
# print("Feature ranking:")
# for f in range(X_train.shape[1]):
#     print("%d. feature %d (%f)" % (f + 1, indices[f], feature_importances[indices[f]]))

# # Plot feature importances
# plt.figure(figsize=(10, 6))
# plt.title("Feature Importances")
# plt.bar(range(X_train.shape[1]), feature_importances[indices], color="b", align="center")
# plt.xticks(range(X_train.shape[1]), indices)
# plt.xlim([-1, X_train.shape[1]])
# plt.xlabel("Feature Index")
# plt.ylabel("Feature Importance")
# plt.show()

"""**Linear Regression**"""

lin_reg_model = LinearRegression()
lin_reg_model.fit(X_train,Y_train)
training_data_prediction = lin_reg_model.predict(X_train)
error_score = metrics.r2_score(Y_train, training_data_prediction)
print("R squared Error : ", error_score)

plt.scatter(Y_train, training_data_prediction)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title(" Actual Prices vs Predicted Prices")
plt.show()

test_data_prediction = lin_reg_model.predict(X_test)
error_score = metrics.r2_score(Y_test, test_data_prediction)
print("R squared Error : ", error_score)
plt.scatter(Y_test, test_data_prediction)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title(" Actual Prices vs Predicted Prices")
plt.show()

"""**Lasso Regression**"""

lass_reg_model = Lasso()
lass_reg_model.fit(X_train,Y_train)
training_data_prediction = lass_reg_model.predict(X_train)
error_score = metrics.r2_score(Y_train, training_data_prediction)
print("R squared Error : ", error_score)
plt.scatter(Y_train, training_data_prediction)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title(" Actual Prices vs Predicted Prices")
plt.show()

test_data_prediction = lass_reg_model.predict(X_test)
error_score = metrics.r2_score(Y_test, test_data_prediction)
print("R squared Error : ", error_score)
plt.scatter(Y_test, test_data_prediction)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title(" Actual Prices vs Predicted Prices")
plt.show()

# """**Neural Network**"""

# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import MinMaxScaler
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Dense
# from tensorflow.keras.optimizers import Adam

# # Assuming df contains your data
# X = df.drop(columns=['Price'])
# y = df['Price']

# # Splitting the data into training, validation, and test sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# # Scaling the features
# scaler = MinMaxScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_val_scaled = scaler.transform(X_val)
# X_test_scaled = scaler.transform(X_test)

# # Changing our epochs and learning rates
# epochs_list = [50, 100, 150]
# learning_rates = [0.001, 0.01, 0.1]

# results = []

# # Iterate over different combinations of hyperparameters
# for epochs in epochs_list:
#     for lr in learning_rates:
#         # Building the neural network model
#         model = Sequential([
#             Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),
#             Dense(64, activation='relu'),
#             Dense(1)
#         ])

#         # Compiling the model
#         optimizer = Adam(learning_rate=lr)  # Updated here
#         model.compile(optimizer=optimizer, loss='mean_squared_error')

#         # Training the model
#         history = model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=32, validation_data=(X_val_scaled, y_val), verbose=0)

#         # Evaluating the model
#         loss = model.evaluate(X_test_scaled, y_test)

#         results.append({
#             'Epochs': epochs,
#             'Learning Rate': lr,
#             'Test Loss': loss
#         })

# # Create a DataFrame to display the results
# results_df = pd.DataFrame(results)

# # Highlighting the best result
# best_result_idx = results_df['Test Loss'].idxmin()
# best_result = results_df.loc[best_result_idx]
# results_df_style = results_df.style.apply(lambda x: ['background: lightgreen' if x.name == best_result_idx else '' for _ in x], axis=1)

# # Plotting actual vs predicted for the best model
# best_model = Sequential([
#     Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),
#     Dense(64, activation='relu'),
#     Dense(1)
# ])
# best_model.compile(optimizer=Adam(learning_rate=best_result['Learning Rate']), loss='mean_squared_error')  # Updated here
# best_model.fit(X_train_scaled, y_train, epochs=int(best_result['Epochs']), batch_size=32, validation_data=(X_val_scaled, y_val), verbose=0)

# y_pred = best_model.predict(X_test_scaled)

# plt.figure(figsize=(10, 6))
# plt.scatter(y_test, y_pred, color='blue')
# plt.title('Actual vs Predicted Prices')
# plt.xlabel('Actual Prices')
# plt.ylabel('Predicted Prices')
# plt.show()

# results_df_style

# from google.colab import drive
# drive.mount('/content/drive')

# from tensorflow.keras.models import load_model
# model.save('/content/drive/MyDrive/saved models/model.hdf5')

# """# Train Test Split"""

# X = df.drop(['Price'], axis=1) #features
# y = df['Price']  #target feature

# from sklearn.model_selection import train_test_split

# X_train, X_test, y_train, y_test = train_test_split(X, y,
#                                                     test_size=0.01,
#                                                     random_state=42,
#                                                     shuffle = True)

# """##Support Vector Classifier"""

# viewer_mode = True
# if viewer_mode:
#   print("Support Vector Classifier takes very long.")
# else:
#   C = 1.0  # SVM regularization parameter
#   models = (svm.SVC(kernel='linear', C=C),
#             svm.SVC(kernel='rbf', gamma=0.7, C=C),
#             svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))


#   accuracy_svc = []
#   for clf in models:
#       clf.fit(X_train_scaled, y_train_scaled)
#       y_pred = clf.predict(X_test_scaled)
#       accuracy_svc.append(accuracy_score(y_test_scaled, y_pred))
#       print(f"Accuracy: ",  accuracy_score(y_test_scaled, y_pred))

# if viewer_mode:
#   max_accuracy_svc=0.734126
#   true_positive_svc=0.660243
#   print('Support Vector Classifier with highest accuracy: Polynomial')
#   print('Accuracy =', max_accuracy_svc)
#   print('Sensitivity (TPR) =', true_positive_svc)
# else:
#   svc_clf_list = ['Linear', 'Radial Basis Function', 'Polynomial']

#   max_accuracy_svc = max(accuracy_svc)
#   max_svc_index = np.argmax(accuracy_svc)

#   svc_clf = models[max_svc_index]
#   svc_clf.fit(X_train_scaled, y_train_scaled)
#   y_predict = svc_clf.predict(X_test_scaled)
#   svc_report = classification_report(y_test, y_predict)

#   cm_svc = confusion_matrix(y_test, y_predict)

#   true_positive_svc = cm_svc[1][1]/sum(y_test)

#   print('Accuracy =', max_accuracy_svc)
#   print('Sensitivity (TPR) =', true_positive_svc)
#   print('Support Vector Classifier with highest accuracy:', svc_clf_list[max_svc_index])

#   print('\n Confusion matrix \n \n')
#   plot_confusion_matrix(svc_clf, X_test_scaled, y_test_scaled)
#   plt.show()

import pickle

pickle.dump(lin_reg_model, open('cloth.pkl', 'wb'))

import joblib

# Assuming encoder is your OrdinalEncoder object
joblib.dump(encoder, 'encoder.pkl')
